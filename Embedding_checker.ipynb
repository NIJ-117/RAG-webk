{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf5befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Load and split the PDF document\n",
    "loader = PyPDFLoader('pdf_files/attention.pdf')\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create the embedding function\n",
    "openai_embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "# Load the documents into Chroma with embeddings\n",
    "openai_db = Chroma.from_documents(splits, openai_embedding_function, persist_directory=\"choma_embeddings/openai_embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6324d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd73d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nij-117/anaconda3/envs/tens/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Documents:\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.comNiki Parmar∗\n",
      "Google Research\n",
      "nikip@google.comJakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.comAidan N. Gomez∗†\n",
      "University of Toronto\n",
      "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring signiﬁcantly\n"
     ]
    }
   ],
   "source": [
    "retriever =openai_db.as_retriever(search_kwargs={\"k\": 1})\n",
    "# Get relevant documents\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the results\n",
    "print(\"Relevant Documents:\")\n",
    "for doc in relevant_documents:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b59d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Set up the environment variable for the Cohere API key\n",
    "os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "# Create the embedding function\n",
    "cohere_embedding_function = CohereEmbeddings()\n",
    "\n",
    "# Load the documents into Chroma with embeddings\n",
    "cohere_db = Chroma.from_documents(splits, cohere_embedding_function, persist_directory=\"choma_embeddings/cohere_embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855bc5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Documents:\n",
      "multi-headed self-attention.\n",
      "For translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\n",
      "on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\n",
      "English-to-French translation tasks, we achieve a new state of the art. In the former task our best\n",
      "model outperforms even all previously reported ensembles.\n",
      "We are excited about the future of attention-based models and plan to apply them to other tasks. We\n",
      "plan to extend the Transformer to problems involving input and output modalities other than text and\n",
      "to investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\n",
      "such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
      "The code we used to train and evaluate our models is available at https://github.com/\n",
      "tensorflow/tensor2tensor .\n",
      "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\n"
     ]
    }
   ],
   "source": [
    "retriever =cohere_db.as_retriever(search_kwargs={\"k\": 1})\n",
    "# Get relevant documents\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the results\n",
    "print(\"Relevant Documents:\")\n",
    "for doc in relevant_documents:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669d70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nij-117/anaconda3/envs/tens/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/nij-117/anaconda3/envs/tens/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# load the document and split it into chunks\n",
    "# Load Documents\n",
    "\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "mpnetdb = Chroma.from_documents(docs, embedding_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274f2da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Documents:\n",
      "Figure 1: The Transformer - model architecture.\n",
      "wise fully connected feed-forward network. We employ a residual connection [ 10] around each of\n",
      "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
      "LayerNorm( x+ Sublayer( x)), where Sublayer(x)is the function implemented by the sub-layer\n",
      "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
      "layers, produce outputs of dimension dmodel = 512 .\n",
      "Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\n",
      "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
      "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
      "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
      "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
      "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position ican depend only on the known outputs at positions less than i.\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
      "query with the corresponding key.\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\n",
      "queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "retriever =mpnetdb.as_retriever(search_kwargs={\"k\": 1})\n",
    "# Get relevant documents\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the results\n",
    "print(\"Relevant Documents:\")\n",
    "for doc in relevant_documents:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d546dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nij-117/anaconda3/envs/tens/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# load the document and split it into chunks\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# load it into Chroma\n",
    "minilmm= Chroma.from_documents(docs, embedding_function,persist_directory=\"choma_embeddings/minilm_embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad96ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Documents:\n",
      "Figure 1: The Transformer - model architecture.\n",
      "wise fully connected feed-forward network. We employ a residual connection [ 10] around each of\n",
      "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
      "LayerNorm( x+ Sublayer( x)), where Sublayer(x)is the function implemented by the sub-layer\n",
      "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
      "layers, produce outputs of dimension dmodel = 512 .\n",
      "Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\n",
      "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
      "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
      "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
      "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
      "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position ican depend only on the known outputs at positions less than i.\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
      "query with the corresponding key.\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\n",
      "queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "retriever = minilmm.as_retriever(search_kwargs={\"k\": 1})\n",
    "# Get relevant documents\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the results\n",
    "print(\"Relevant Documents:\")\n",
    "for doc in relevant_documents:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e58f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
