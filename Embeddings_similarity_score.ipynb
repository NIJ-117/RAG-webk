{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6MDms2oti4T"
   },
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uw_SDekvtksi",
    "outputId": "495e77d6-7ff9-4667-d647-3086b201a591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: tensor([[0.2601, 0.0635, 0.0499, 0.0336]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "# 1. Specify preffered dimensions\n",
    "dimensions = 512\n",
    "\n",
    "# 2. load model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# For retrieval you need to pass this prompt.\n",
    "query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread while a girl is wathing him'\n",
    "\n",
    "docs = [\n",
    "    query,\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating pasta.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "]\n",
    "\n",
    "# 2. Encode\n",
    "embeddings = model.encode(docs)\n",
    "\n",
    "# Optional: Quantize the embeddings\n",
    "binary_embeddings = quantize_embeddings(embeddings, precision=\"ubinary\")\n",
    "\n",
    "similarities = cos_sim(embeddings[0], embeddings[1:])\n",
    "print('similarities:', similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yc3ORv9vtku6",
    "outputId": "9f9af9c0-1c5d-4648-a913-c7907903f397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: tensor([[0.6357, 0.4859, 0.2854, 0.2616]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "# 1. Specify preffered dimensions\n",
    "dimensions = 512\n",
    "\n",
    "# 2. load model\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dimensions)\n",
    "\n",
    "# For retrieval you need to pass this prompt.\n",
    "query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread while a girl is wathing him'\n",
    "\n",
    "docs = [\n",
    "    query,\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating pasta.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "]\n",
    "\n",
    "# 2. Encode\n",
    "embeddings = model.encode(docs)\n",
    "\n",
    "# Optional: Quantize the embeddings\n",
    "binary_embeddings = quantize_embeddings(embeddings, precision=\"ubinary\")\n",
    "\n",
    "similarities = cos_sim(embeddings[0], embeddings[1:])\n",
    "print('similarities:', similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0jBNW7vtkxr",
    "outputId": "e50aba8d-bb70-4710-f727-524c62385b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: tensor([[0.3144, 0.1944, 0.1033, 0.0252]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "# 1. Specify preffered dimensions\n",
    "dimensions = 512\n",
    "\n",
    "# 2. load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# For retrieval you need to pass this prompt.\n",
    "query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread while a girl is wathing him'\n",
    "\n",
    "docs = [\n",
    "    query,\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating pasta.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "]\n",
    "\n",
    "# 2. Encode\n",
    "embeddings = model.encode(docs)\n",
    "\n",
    "# Optional: Quantize the embeddings\n",
    "binary_embeddings = quantize_embeddings(embeddings, precision=\"ubinary\")\n",
    "\n",
    "similarities = cos_sim(embeddings[0], embeddings[1:])\n",
    "print('similarities:', similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vl-bj4snulue",
    "outputId": "b6c64ea2-e119-4a20-8751-06435cb353a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: [[0.8572839  0.83922635 0.7889852  0.79171162]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = 'Open-AI-key'\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Define the query and documents\n",
    "query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread while a girl is watching him'\n",
    "\n",
    "docs = [\n",
    "    query,\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating pasta.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "]\n",
    "\n",
    "# Function to get embeddings using LangChain's OpenAI integration\n",
    "def get_openai_embeddings(documents):\n",
    "    embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    embeddings = embeddings_model.embed_documents(documents)\n",
    "    return embeddings\n",
    "\n",
    "# Encode the documents\n",
    "embeddings = get_openai_embeddings(docs)\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Calculate cosine similarities between the query and other documents\n",
    "similarities = cosine_similarity([embeddings_array[0]], embeddings_array[1:])\n",
    "print('similarities:', similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AV_9z18DulxO"
   },
   "outputs": [],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFpyLNkiul1N"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neBwBOT21leH"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xhm_PInA03XD",
    "outputId": "6340bb38-b4b5-4180-9f18-21a833312d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: [[0.5669538  0.42870585 0.32511208 0.21893115]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cohere\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Set the Cohere API key\n",
    "os.environ['COHERE_API_KEY'] = 'Cohere-API-key'\n",
    "cohere_api_key = os.environ['COHERE_API_KEY']\n",
    "\n",
    "# Define the query and documents\n",
    "query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread while a girl is watching him'\n",
    "\n",
    "docs = [\n",
    "    query,\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating pasta.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "]\n",
    "\n",
    "# Function to get embeddings using LangChain's Cohere integration\n",
    "def get_cohere_embeddings(documents):\n",
    "    embeddings_model = CohereEmbeddings(model=\"embed-english-light-v2.0\")\n",
    "    embeddings = embeddings_model.embed_documents(documents)\n",
    "    return embeddings\n",
    "\n",
    "# Encode the documents\n",
    "embeddings = get_cohere_embeddings(docs)\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Calculate cosine similarities between the query and other documents\n",
    "similarities = cosine_similarity([embeddings_array[0]], embeddings_array[1:])\n",
    "print('similarities:', similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFLJmb9e1oA_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
